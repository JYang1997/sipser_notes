# Random notes about language
### 1.
	There are three different terms,
	1. language
	2. language generator (grammar of the language)
	3. language recognizer (machine (automaton))
1. **language** are represent in the form of expressions (regular expression, context-free expression)
2. **grammar** specified rules for generating the language.
3. **automaton** is a machine that recognize the language.

### 2.
Pumping lemma is useful for proving a language is not CFL or RL.

Basic Idea:
1. If the language size is **finite**, then it is obvious. (RL)
2. If the language size is not **finite**, then by pigeonhole, there must be part of the rule reused.
3. This reuse of rule lead to loop in the path, then remove such loop, or repeat multiple times should not affect acceptance of the string.


# Chapter 1 Regular Language
> **Definition**
> A **finite automaton** is a 5-tuple $(Q, \Sigma , \delta, q_0 F)$, where
> 1. Q is a finite set called the **states**.
> 2.  $\Sigma$ is a finite set called the **alphabets**.
> 3. $\delta : Q \times \Sigma \rightarrow Q$ is the transition function.
> 4. $q_0 \in Q$ is the start state
> 5. $F \subseteq Q$ is the set of  accept states.
>
> A **nondeterministic finite automaton** allow $\epsilon$ transition, that is,
> 3. $\delta : Q \times \Sigma_\epsilon \rightarrow Q$ is the transition function.

> **Theorem**
> Every nondeterministic finite automaton has an equivalent deterministic finite automaton.
 

Finite automaton is the recognizers for equivalent **Regular Languages**. Another words, Regular Languages are exactly the languages accepted by (non)deterministic finite automata;


> **Definition**
>  Formal definition for **Regular Expression** if R is 
>  1. $a$ for some $a$ in the alphabet $\Sigma$,
>  2. $\epsilon$
> 3. $\empty$
> 4. $(R_1 \cup R_2 )$, where $R_1$ and $R_2$ are regular expressions,
> 5. (R 1 ◦ R 2 ), where $R_1$ and $R_2$ are regular expressions, or
> 6. $(R_1^* )$, where $R_1$ is a regular expression.
In items 1 and 2, the regular expressions a and ε represent the
languages {a} and {ε}, respectively. In item 3, the regular expres-
sion ∅ represents the empty language. In items 4, 5, and 6, the
expressions represent the languages obtained by taking the union
or concatenation of the languages R 1 and R 2 , or the star of the
language R 1 , respectively.
 
 ### Differentiating Non-Regular Languages 
To differentiating  regularities, we can use **Pumping lemma**

> **Pumping Lemma**
>   If $A$ id a regular language, then there is a number $p$ (the pumping length) where if $s$ is any string in $A$ of length at least $p$, then $s$ may be divided into three pieces, $s = xyz$, satisfying the following conditions:
>   >1. for each $i \geq 0$, $xy^iz \in A$,
>   >2. $|y| > 0$, and
>   >3. $|xy| \leq p$.

The proof is really trivial (based on pigeonhole principle).

The pumping lemma is useful when you try to prove a language is not regular.
But this theorem is not really useful if you try to prove a language **is** regular.
The pumping lemma is a one way statement, says nothing about non-regular language.
Showing second part is not sufficient for proving the language is regular.

To prove a language is regular, one can start from the definition, or its equivalent models.

#### Strategies for using pumping lemma.
1.  Start with proof by contradiction.
2.  Choose a particular string, with length $\geq p$. (choose a string that break the rule when pump).
3.  Then use the fact that $|xy| \leq p$, to help you break the pumpable property
4.  Last, show for which choice of $i$ in $xy^iz$ where such property break.

> **Example**
> Show that $AB1 = \{a^ib^j : i \geq j\}$ is not regular.
> >***note***: we want to break the property where $i \geq j$  
> 1. A assume $AB1$ is regular.
> 2. Let $\omega = "a^nb^n"$ //setting a, b length equal to each other still in the language. then we break it by pump away a to make first part smaller.
> 3. Then by definition $xy = a^m$, where $m \leq n$ must be true.
> 4. let $i = 0$, contradiction. QED
#### Second approach for proving non-regular: use the definition, show that the language is not closed under Concatenation, Union or Kleene star. 

# Chapter 2 Context Free Language
	 
### TODO:
	1. show inherently ambiguous
	2. if language is generatable, can you always built equivalent machine recognize it?.
	3. complete example when review for exam
>**Definition**
> CFG is 4-tuple $(V, \Sigma, R, S)$
> 1. V is a finite set called variables
> 2. $\Sigma$ is a finite set called terminals (disjoint from V).
> 3. R is a finite set of rules
> 4. $S \in V$ is a start varible.

>**Definition**
> A **context free laguage** is any language that is generated by a context-free grammar. (CFL)



>**Definition**
>A string $\omega$ is derived **ambiguously** in context-free grammar G if it has two or more different **leftmost derivations**. Grammar G is ambiguous if it generates some string ambiguously.
> 
> ***leftmost derivation**:  if at every step the leftmost remaining variable is the one replaced.

>**Theorem**
> Any CFL is generated by a CFG in Chomsky normal form


> **Definition**
>  A **pushdown automaton** is a 6-tuple $(Q, \Sigma, \Gamma , \delta, q_0, F)$, where $Q, \Sigma, \Gamma$, and $F$ are all finite sets, and
>  > 1. $Q$ is set of states
>  > 2. $\Sigma$ is the input alphabet,
>  > 3. $\Gamma$ is the stack alphabet,
>  > 4.  $\delta : Q \times \Sigma_\epsilon \times \Gamma_\epsilon \rightarrow P(Q \times \Gamma_\epsilon)$ is the transition function.
>  > 5. $q_0 \in Q$ is the start state.
>  > 6. $F \subseteq Q$ is the set accept states.


> **Theorem 2.20**
> A language is context free if and only if some pushdown automaton recognizes it.

The proof for above theorem is redious, basically it's a proof by construction, where it shows that start from one of it you can construct the other one.


### Differentiating Non-Context-Free Languages

> **Pumping Lemma for Context-Free Languages**
> If $A$ is context-free language, then there is a number $p$ (the pumping length) where, if $s$ is any in $A$ of length at least $p$, then $s$ may be divided into five pieces  $s = uvxyz$ satisfying the conditions,
> >1. for each $i \geq 0$, $uv^ixy^iz \in A$
>> 2. $|uy| > 0$
>>3. $|vxy| \leq p$.

The **pumping length** has upper bound $b^{|V|+1}$, where $|V|$ is the number of variables in the grammar, and b is the maximum number of symbols in the right hand side of a rule. 
This pumping length implies that the strings greater than such length must have parse tree at least
$|V|+1$ high, because $b^{|V|+1} \geq b^{|V|}+1$.
Which immediately follow that there must be loop in the derivation.

>**Example**


# Chapter 3 The Church-Turing Thesis

### TODO:
		1.go through TM examples in ch 3.1
		
>**Definition**
> A **Turing machine** is a 7-tuple, $(Q, Σ, Γ, δ, q_0 , q_{accept} , q_{reject} )$, where
$Q, Σ, Γ$ are all finite sets and
> 1. $Q$ is the set of states,
> 2. $Σ$ is the input alphabet not containing the blank symbol ␣ ,
> 3. $Γ$ is the tape alphabet, where $␣ ∈ Γ$ and $Σ ⊆ Γ$,
> 4. $δ : Q × Γ \rightarrow Q × Γ × \{L, R\}$ is the transition function,
> 5. $q_0 ∈ Q$ is the start state,
> 6. $q_{accept} ∈ Q$ is the accept state, and
> 7. $q_{reject} ∈ Q$ is the reject state, where $q_{reject} \neq q_{accept}$

Turing Machines computation process are represented by **configuration**. Configuration describes TM's current state, the current tape contents, and the current head location. The transition function $δ$ describes how TM's changes from one configuration to another. We say configuration 1 **yields** configuration 2, if there is transition function that go from 1 to 2. 
> typically **configuration** are represented as $u q v$, where $uv$ is the input string. The $q$ represent the current state of TM. and the head of TM is pointed to the first symbol of string $v$. 

#### Decidable v.s. Recognizable
> **Definition**
>  Call a language **Turing-recogniziable** if some Turing machine recognizes it.

> **Definition**
> Call a language **Turing-decidable** or simply **decidable** if some Turing machine decides it.

The difference between deciadable and recognizable is that, for Turing decidable, there are a turing machine that recognize such language and it always accept or reject, never **halts**. 
Turing-Recognizable only guarantee that if string is in such language than turing machine accepts it, said nothing about what happen if machine does not accept it. (Both halt and reject is possible).

#### Robustness of Turing Machines
The Turing machine have very high level of robustness. This basically means that the original turing machine model have equivalence expressing power (recognize) compare to its reasonable variants (those variants may seems more powerful, but we can show that all the add-on "features" can be simulated with original turing machine.)

Here are some example variants that are equivalence to the Turing machine.

1. multitape turing machine (Thm 3.13)
2. non-deterministic Turing machine (Thm 3.16)
3. stay put turing machine.

In general, one can demonstrate the equivalence by showing that the variant part can be simulates using plain Turing Machine. (see section 3.2, for details)

## The definition of  Algorithm
	> TODO read scan turing 1936, then add more detail here
The Church-Turing thesis provides the definition of algorithm. This fomalized the intuitive notion of algorithms.

When talking about algorithm or more specifically **Turing Machine Algorithm**. There are three different level of description.
	
 1. formal description: use the definition of turing machine, write out every details, includes transitions functions and states etc.
 2.  Implementation description: use more simple english descprition for how Turing machine's head move and the way that its stores data, etc.
 3. high level description: you can think of it as pseudo code. 


# Chapter 4 Decidability

*The previous section (algorithm) implies that:
Asking whether certain **Turing Machine algorithm** exist for a problem,
is same as asking whether such problem is **Turing-Decidable**.*

### Decidable problems concerning Regular Languages
> **Theorem 4.1** $A_{DFA}$ is decidable language.
> **Theorem 4.2** $A_{NFA}$ is decidable language
> **Theorem 4.3**  $A_{REX}$ is decidable language.

$A_{DFA}$ is a language, defined as:
$A_{DFA}$ = \{$<B,w>$ | $B$ is a DFA that accepts input string $w$\}
The **acceptance problem** for DFAs of testing whether a particular DFA accepts a given string $w$ can be expressed as language $A_{DFA}$. 

Then, asking whether such acceptance problem is decidable by Turing-Machine is same asking whether language $A_{DFA}$ is decidable.

To determine whether such language is decidable, we can show that there exist a TM *M* that decides $A_{DFA}$. The basic proof idea for Theorem 4.1 is to simulate DFA *B* on turing machine.

**Theorem 4.1-3** are essentially equivalent.  One can convert NFA or  REX to DFA then use DFA as part of the input, then 2 and 3 are obviously true.

##### Emptiness problem:
> **Theorem 4.4** $E_{DFA}$ is decidable language.

$E_{DFA}$ = \{$<A>$ | *A* is a DFA and $L(A)=\empty$\}

Theorem 4.4 can be prove using iterative marking algorithm. Starting from initial state, mark it. Then mark all state with marked state as incoming state. Finally accept is no accept state is marked. Otherwise, reject.

> **Theorem 4.5** $EQ_{DFA}$ is a decidable language.

$EQ_{DFA} =$ \{$<A,B>$ | *A* and *B* are DFAs and $L(A) = L(B)$\}

Theorem 4.5 state that determine whether two DFAs are equivalent is decidable.
The proof idea:
If DFA *A* and *B* is not equivalent, then there must be strings that only accept by either A or B.  (known as **symmetric difference** of *A* and *B*). 

 $L(C) = (L(A) \cap \overline{L(B)}) \cup (\overline{L(A)} \cap L(B))$

then if both DFA is equivalent, we know their symmetric difference must be empty. Therefore proving A and B are equivalent is same as deciding $L(C)$ is empty. Note, DFA is closed under these operations, then we can construct C based on A and B, then run emptiness decider (DFA emptiness decider) for C.  QED.

### Decidable problems concerning Context-Free Languages

> **Theorem 4.7** $A_{CFG}$ is a decidable language.

$A_{CFG} =$ \{$<G,w>$ | *G* is a *CFG* that generates string $w$\}
The basic proof idea is to convert CFG to its **Chomsky normal form**, then any derivation can be decided in a finite number of step (2n+1, where n is length of w).

>**Theorem 4.8** $E_{CFG}$ is a decidable language.
$E_{CFG} =$ \{$<G>$ | *G* is a *CFG* and $L(G) = \empty$\}

The basic idea for proving emptiness problem for CFG is to follow marking algorithm. You start from terminals of CFG, then reach up, see whether eventually the start symbol got marked. If start symbol marked then basically it means there is a way that start symbol can reach terminals. Hence, reject.

>**Theorem 4.9** Every context-free language is decidable.

We can use the machine from Thm 4.7, then put the desired CFG as input, we can decide whether a string is belong to such CFL. 


>**Fact**
>$EQ_{CFG}$ is not decidable, proof will be shown in next chapter.


**Decidable Summary**
From Thm 4.9, we now know that:
$regular \sub context free\sub decidable \sub Turing recognizable$

There are correponding recognizer machine for regular and context free language. For decidable language, it's recognizer is basically the corresponding turing machine that always halts.

## Undecidability

>**Theorem 4.11**
>$A_{TM} = \{<M,w>| m \text{ is a } TM \text\}\text{ss ss}$



# Chapter 5 Reducibility
> Written with [StackEdit](https://stackedit.io/).


<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE1ODc5NzczOTEsMTI5MDIzMTIwNSwtMj
A2NDQ5MDM2MiwtMTgyMzg5Mjc1NywtMTQ5ODIzNTk4MSwtNzMy
ODgzMDE2XX0=
-->